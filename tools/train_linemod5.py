# --------------------------------------------------------
# DenseFusion 6D Object Pose Estimation by Iterative Dense Fusion
# Licensed under The MIT License [see LICENSE for details]
# Written by Chen
# --------------------------------------------------------

import _init_paths
import argparse
import os
import random
import time
import numpy as np
import torch
from torch import utils
from torch import manual_seed, load
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data as data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from datasets.ycb.dataset import PoseDataset as PoseDataset_ycb
# from datasets.linemod.dataset import PoseDataset as PoseDataset_linemod
from datasets.linemod5.dataset import PoseDataset as PoseDataset_linemod5
from lib.network import PoseNet, PoseRefineNet
from lib.loss import Loss
from lib.loss_refiner import Loss_refine
from lib.utils.utils import setup_logger
from torch.amp import GradScaler, autocast

scaler = GradScaler(device='cuda')


parser = argparse.ArgumentParser()
parser.add_argument('--dataset', type=str, default = 'linemod', help='ycb or linemod')
parser.add_argument('--dataset_root', type=str, default = '', help='dataset root dir (''YCB_Video_Dataset'' or ''Linemod_preprocessed'')')
parser.add_argument('--batch_size', type=int, default = 1, help='batch size')
parser.add_argument('--workers', type=int, default = 4, help='number of data loading workers')
parser.add_argument('--lr', default=0.0001, help='learning rate')
parser.add_argument('--lr_rate', default=0.3, help='learning rate decay rate')
parser.add_argument('--w', default=0.015, help='learning rate')
parser.add_argument('--w_rate', default=0.3, help='learning rate decay rate')
parser.add_argument('--decay_margin', default=0.016, help='margin to decay lr & w')
parser.add_argument('--refine_margin', default=0.013, help='margin to start the training of iterative refinement')
parser.add_argument('--noise_trans', default=0.03, help='range of the random noise of translation added to the training data')
parser.add_argument('--iteration', type=int, default = 2, help='number of refinement iterations')
parser.add_argument('--nepoch', type=int, default=500, help='max number of epochs to train')
parser.add_argument('--resume_posenet', type=str, default = '/pose_model_3_0.007043762697527806.pth',  help='DS_LSKA_0915_pose_model_3_0.009499964444953412.pth')
parser.add_argument('--resume_refinenet', type=str, default = '/pose_refine_model_5_0.005734924412487696.pth',  help='DS_LSKA_0915_pose_refine_model_37_0.00676745064561135.pth')
parser.add_argument('--start_epoch', type=int, default = 1, help='which epoch to start')
parser.add_argument('--k', type=int, default = 20, help='knn')
opt = parser.parse_args()

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

def plot_point_clouds(points1, points2):
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(points1[:,0], points1[:,1], points1[:,2], s=1, c='r', label="model_points (pred)")
    ax.scatter(points2[:,0], points2[:,1], points2[:,2], s=1, c='b', label="target (GT)")
    ax.legend()
    plt.show()

def main():
# éšæœºæ•°è®¾ç½® ?
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

    opt.manualSeed = random.randint(1, 10000)
    random.seed(opt.manualSeed) # è®¾ç½® random æ¨¡å—çš„éšæœºæ•°ç”Ÿæˆå™¨ç§å­ä¸º opt.manualSeed
    manual_seed(opt.manualSeed) #  è®¾ç½® PyTorch ä¸­çš„éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­
# æ•°æ®é›†å‚æ•°è®¾ç½®
    if opt.dataset == 'ycb':
        opt.num_objects = 21 #number of object classes in the dataset
        opt.num_points = 1000 #number of points on the input pointcloud
        opt.outf = '/media/q/SSD2T/1linux/YCB_trained_models' #folder to save trained models
        opt.log_dir = '/media/q/SSD2T/1linux/YCB_log' #folder to save logs
        opt.repeat_epoch = 1 #number of repeat times for one epoch training
    elif opt.dataset == 'linemod':
        opt.num_objects = 1
        opt.num_points = 1000
        opt.outf = '/media/q/SSD2T/1linux/Linemod5_trained_mod' # è®¾ç½®è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜æ¨¡åž‹çš„æ–‡ä»¶å¤¹è·¯å¾„
        opt.log_dir = '/media/q/SSD2T/1linux/Linemod5_log' # è®¾ç½®è®­ç»ƒè¿‡ç¨‹ä¸­æ—¥å¿—ä¿å­˜çš„ç›®å½•
        opt.repeat_epoch = 8 # è®¾ç½®æ¯ä¸ªç‰©ä½“è®­ç»ƒçš„é‡å¤è½®æ•°ä¸º 20
    else:
        print('Unknown dataset')
        return



# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” è®­ç»ƒã€ä¼˜åŒ–ç½‘ç»œå®žä¾‹åŒ–â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    estimator = PoseNet(num_points = opt.num_points, num_obj = opt.num_objects)
    estimator.cuda()
    refiner = PoseRefineNet(num_points = opt.num_points, num_obj = opt.num_objects)
    refiner.cuda()

# ç½‘ç»œé—´æ–­ç‚¹è®¾ç½®
    if opt.resume_posenet != '':
        estimator.load_state_dict(load('{0}/{1}'.format(opt.outf, opt.resume_posenet)))
    if opt.resume_refinenet != '':
        refiner.load_state_dict(load('{0}/{1}'.format(opt.outf, opt.resume_refinenet)))
        opt.refine_start = True
        opt.decay_start = True
        opt.lr *= opt.lr_rate
        opt.w *= opt.w_rate
        opt.batch_size =max( 1,int(opt.batch_size / opt.iteration))
        optimizer = optim.Adam(refiner.parameters(), lr=opt.lr)
    else:
        opt.refine_start = False
        opt.decay_start = False
        optimizer = optim.Adam(estimator.parameters(), lr=opt.lr)

# æ•°æ®åŠ è½½
    if opt.dataset == 'ycb':
        dataset = PoseDataset_ycb('train', opt.num_points, True, opt.dataset_root, opt.noise_trans, opt.refine_start)
    elif opt.dataset == 'linemod':
        dataset = PoseDataset_linemod5('train', opt.num_points, True, opt.dataset_root, opt.noise_trans, opt.refine_start)
    dataloader = utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=opt.workers)
    if opt.dataset == 'ycb':
        test_dataset = PoseDataset_ycb('test', opt.num_points, False, opt.dataset_root, 0.0, opt.refine_start)
    elif opt.dataset == 'linemod':
        test_dataset = PoseDataset_linemod5('test', opt.num_points, False, opt.dataset_root, 0.0, opt.refine_start)
    testdataloader = utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=opt.workers)

# å¯¹ç§°ä¿¡æ¯èŽ·å–
    opt.sym_list = dataset.get_sym_list()
    opt.num_points_mesh = dataset.get_num_points_mesh() # æ•°æ®é›†ä¸­ç½‘æ ¼æ¨¡åž‹çš„ç‚¹æ•°

    print('>>>>>>>>----------Dataset loaded!---------<<<<<<<<\nlength of the training set: {0}\nlength of the testing set: {1}\nnumber of sample points on mesh: {2}\nsymmetry object list: {3}'.format(len(dataset), len(test_dataset), opt.num_points_mesh, opt.sym_list))

#â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” æŸå¤±å‡½æ•°â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    criterion = Loss(opt.num_points_mesh, opt.sym_list)
    criterion_refine = Loss_refine(opt.num_points_mesh, opt.sym_list)

# æµ‹è¯•è®¾ç½®
    best_test = np.inf

    # æ¸…ç©ºæ—¥å¿—
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—ç›®å½•
    st_time = time.time()
    time_str = time.strftime("%Y%m%d_%H%M%S", time.localtime(st_time))
    log_dir = os.path.join(opt.log_dir, time_str)

    # å¦‚æžœç›®å½•ä¸å­˜åœ¨ï¼Œå°±åˆ›å»º
    os.makedirs(log_dir, exist_ok=True)
    print(f"æœ¬æ¬¡è®­ç»ƒæ—¥å¿—ä¿å­˜åˆ°: {log_dir}")

    for epoch in range(opt.start_epoch, opt.nepoch):
        torch.cuda.empty_cache()
        # æ—¥å¿—
        logger = setup_logger('epoch%d' % epoch, os.path.join(log_dir, 'epoch_%d_log.txt' % epoch))
        logger.info('Train time {0}'.format(time.strftime("%Hh %Mm %Ss", time.gmtime(time.time() - st_time)) + ', ' + 'Training started'))
        # trainçš„flag
        train_count = 0
        train_dis_avg = 0.0

        # æ˜¯å¦è®­ç»ƒä¼˜åŒ–
        if opt.refine_start:
            estimator.eval()
            refiner.train()
        else:
            estimator.train()
        # optimizer.zero_grad() # æ¸…é™¤ä¸Šä¸€è½®è®¡ç®—çš„æ¢¯åº¦
        # Estimator å‚æ•°é‡
        estimator_params = sum(p.numel() for p in estimator.parameters() if p.requires_grad)
        print("Estimator Params:", estimator_params)

        # Refiner å‚æ•°é‡
        refiner_params = sum(p.numel() for p in refiner.parameters() if p.requires_grad)
        print("Refiner Params:", refiner_params)
        # é‡å¤è®­ç»ƒè½®æ¬¡
        for rep in range(opt.repeat_epoch):
            for i, data in enumerate(dataloader, 0):
                points, choose, img, target, model_points, idx = data
                points, choose, img, target, model_points, idx = points.cuda(), \
                                                                 choose.cuda(), \
                                                                 img.cuda(), \
                                                                 target.cuda(), \
                                                                 model_points.cuda(), \
                                                                 idx.cuda()

                # pointsï¼šæ·±åº¦æŽ©ç åŽçš„ç‚¹äº‘
                # chooseï¼šä¸€ä¸ªç´¢å¼•æ•°ç»„ï¼ŒæŒ‡ç¤ºå“ªäº›ç‚¹è¢«é€‰ä¸­ï¼Œç”¨äºŽè®­ç»ƒæˆ–è¯„ä¼°ã€‚
                # imgï¼šå›¾åƒæ•°æ®ï¼Œç»è¿‡å½’ä¸€åŒ–çš„RGBå›¾åƒã€‚
                # targetï¼šç›®æ ‡çš„ 3D ç‚¹äº‘åæ ‡ï¼Œç»è¿‡å˜æ¢åŽçš„ç‰©ä½“æ¨¡åž‹ç‚¹äº‘æ•°æ®ã€‚
                # model_pointsï¼šç‰©ä½“æ¨¡åž‹çš„ 3D ç‚¹äº‘æ•°æ®ã€‚
                # idxï¼šç‰©ä½“çš„ç´¢å¼•ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤ºè¯¥æ ·æœ¬æ‰€å±žçš„ç‰©ä½“ç±»åˆ«ã€‚
                # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”ä½å§¿ä¼°è®¡â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
                with autocast(device_type='cuda'):
                    pred_r, pred_t, pred_c, emb = estimator(img, points, choose, idx)
                    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”æŸå¤±å‡½æ•°â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
                    loss, dis, new_points, new_target = criterion(pred_r, pred_t, pred_c, target, model_points, idx, points, opt.w,opt.refine_start, opt.num_points_mesh, opt.sym_list)
                #â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”ä¼˜åŒ–â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
                if opt.refine_start:
                    optimizer.zero_grad(set_to_none=True)
                    for ite in range(0, opt.iteration):
                        with autocast(device_type='cuda'):
                            pred_r, pred_t = refiner(new_points, emb, idx)
                            dis, new_points, new_target = criterion_refine(pred_r, pred_t, new_target, model_points, idx, new_points)
                        scaler.scale(dis).backward()
                        scaler.step(optimizer)
                        scaler.update()

                        # ðŸ”¥ æ–­è®¡ç®—å›¾ï¼ˆå¿…é¡»ï¼‰
                        new_points = new_points.detach()
                        new_target = new_target.detach()
                        emb = emb.detach()
                else:
                    optimizer.zero_grad(set_to_none=True)
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()

                # torch.nn.utils.clip_grad_norm_(estimator.parameters(), max_norm=1.0)
                # disæ˜¯é¢„æµ‹ç‚¹å’Œç›®æ ‡ç‚¹çš„è·ç¦»ï¼Œ
                train_dis_avg += dis.item()
                train_count += 1
                # print("pred_t:", pred_t[0].detach().cpu().numpy())
                # print("pred_r norm:",  pred_r[0].detach().cpu().numpy())
                if train_count % 20 == 0:
                    logger.info('Train time {0} Epoch {1} Batch {2} Frame {3} Avg_dis:{4}'.format(time.strftime("%Hh %Mm %Ss", time.gmtime(time.time() - st_time)), epoch, int(train_count / opt.batch_size), train_count, train_dis_avg / opt.batch_size))
                    # optimizer.step()
                    # optimizer.zero_grad() # æ¸…é™¤ä¸Šä¸€è½®è®¡ç®—çš„æ¢¯åº¦
                    train_dis_avg = 0

                if train_count != 0 and train_count % 1000 == 0:
                    if opt.refine_start:
                        torch.save(refiner.state_dict(), '{0}/pose_refine_model_current.pth'.format(opt.outf))
                    else:
                        torch.save(estimator.state_dict(), '{0}/pose_model_current.pth'.format(opt.outf))
        print('>>>>>>>>----------epoch {0} train finish---------<<<<<<<<'.format(epoch))
        logger = setup_logger('epoch%d_test' % epoch, os.path.join(log_dir, 'epoch_%d_test_log.txt' % epoch))
        logger.info('Test time {0}'.format(time.strftime("%Hh %Mm %Ss", time.gmtime(time.time() - st_time)) + ', ' + 'Testing started'))
        test_dis = 0.0
        test_count = 0
        estimator.eval()
        refiner.eval()

        for j, data in enumerate(testdataloader, 0):
            points, choose, img, target, model_points, idx = data
            points, choose, img, target, model_points, idx = points.cuda(), \
                                                             choose.cuda(), \
                                                             img.cuda(), \
                                                             target.cuda(), \
                                                             model_points.cuda(), \
                                                             idx.cuda()
            with torch.no_grad():
                with autocast(device_type='cuda'):
                    pred_r, pred_t, pred_c, emb = estimator(img, points, choose, idx)
                    _, dis, new_points, new_target = criterion(pred_r, pred_t, pred_c, target, model_points, idx, points, opt.w, opt.refine_start, opt.num_points_mesh, opt.sym_list)

                if opt.refine_start:
                    for ite in range(0, opt.iteration):
                            with autocast(device_type='cuda'):
                                pred_r, pred_t = refiner(new_points, emb, idx)
                                dis, new_points, new_target = criterion_refine(pred_r, pred_t, new_target, model_points, idx, new_points)

            test_dis += dis.item()
            logger.info('Test time {0} Test Frame No.{1} dis:{2}'.format(time.strftime("%Hh %Mm %Ss", time.gmtime(time.time() - st_time)), test_count, dis))


            test_count += 1

        test_dis = test_dis / test_count
        logger.info('Test time {0} Epoch {1} TEST FINISH Avg dis: {2}'.format(time.strftime("%Hh %Mm %Ss", time.gmtime(time.time() - st_time)), epoch, test_dis))
        logger.info("pred_r range: [{:.4f}, {:.4f}], pred_t range: [{:.4f}, {:.4f}]".format(
            pred_r.min().item(), pred_r.max().item(),
            pred_t.min().item(), pred_t.max().item()))
        if j == 0:  # åªçœ‹ç¬¬ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
            # å‡è®¾ model_points, target æ˜¯ torch.Tensor
            plot_point_clouds(new_points.cpu().numpy(), new_target.cpu().numpy())

            break

        if test_dis <= best_test:
            best_test = test_dis
            if opt.refine_start:
                torch.save(refiner.state_dict(), '{0}/pose_refine_model_{1}_{2}.pth'.format(opt.outf, epoch, test_dis))
            else:
                torch.save(estimator.state_dict(), '{0}/pose_model_{1}_{2}.pth'.format(opt.outf, epoch, test_dis))
            print(epoch, '>>>>>>>>----------BEST TEST MODEL SAVED---------<<<<<<<<')

        # è°ƒèŠ‚è¡°å‡çŽ‡
        if best_test < opt.decay_margin and not opt.decay_start:
            opt.decay_start = True
            opt.lr *= opt.lr_rate
            opt.w *= opt.w_rate
            optimizer = optim.Adam(estimator.parameters(), lr=opt.lr)

        # è°ƒèŠ‚è¡°å‡çŽ‡
        if best_test < opt.refine_margin and not opt.refine_start:
            opt.refine_start = True
            opt.batch_size = max(1, int(opt.batch_size / opt.iteration))
            # opt.batch_size = int(opt.batch_size / opt.iteration)
            optimizer = optim.Adam(refiner.parameters(), lr=opt.lr)


            if opt.dataset == 'ycb':
                dataset = PoseDataset_ycb('train', opt.num_points, True, opt.dataset_root, opt.noise_trans, opt.refine_start)
            elif opt.dataset == 'linemod':
                dataset = PoseDataset_linemod5('train', opt.num_points, True, opt.dataset_root, opt.noise_trans, opt.refine_start)
            dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=opt.workers)
            if opt.dataset == 'ycb':
                test_dataset = PoseDataset_ycb('test', opt.num_points, False, opt.dataset_root, 0.0, opt.refine_start)
            elif opt.dataset == 'linemod':
                test_dataset = PoseDataset_linemod5('test', opt.num_points, False, opt.dataset_root, 0.0, opt.refine_start)
            testdataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=opt.workers)
            
            opt.sym_list = dataset.get_sym_list()
            opt.num_points_mesh = dataset.get_num_points_mesh()

            print('>>>>>>>>----------Dataset loaded!---------<<<<<<<<\nlength of the training set: {0}\nlength of the testing set: {1}\nnumber of sample points on mesh: {2}\nsymmetry object list: {3}'.format(len(dataset), len(test_dataset), opt.num_points_mesh, opt.sym_list))

            criterion = Loss(opt.num_points_mesh, opt.sym_list)
            criterion_refine = Loss_refine(opt.num_points_mesh, opt.sym_list)

if __name__ == '__main__':
    main()
